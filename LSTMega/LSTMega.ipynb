{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMega\n",
    "\n",
    "Este projeto é um modelo de rede neural recorrente utilizando a arquitetura *Long Short-Term Memory* &ndash; LSTM para geração automatizada de textos.\n",
    "\n",
    "Ele está baseado em uma implementação da biblioteca [Keras](https://keras.io/) e foi iniciado a partir de um exemplo da utilização de redes neurais recorrentes com LSTM, onde este foi disponibilizado na própria documentação do Keras e pode ser acessado [aqui](https://keras.io/examples/lstm_text_generation/).\n",
    "\n",
    "Todo o projeto e histórico de mudanças está disponível no repositório [lstmega](https://github.com/mlc2307/lstmega) no GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As bibliotecas base deste projeto são a Keras e o [TensorFlow](https://www.tensorflow.org/). Elas serão carregadas durante todo o processo.\n",
    "\n",
    "É valido lembrar que nem todas as bibliotecas são importadas no exemplo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deve estar na primeira linha.\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib as dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retorna informações sobre o computador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa a GPU que será utilizada no treinamento.\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista os dispositivos locais.\n",
    "dlib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliotecas que são utilizadas no decorrer da aplicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ferramentas para leitura do texto.\n",
    "from keras.utils.data_utils import get_file\n",
    "from os.path import basename\n",
    "import io\n",
    "\n",
    "# Para a geração dos arrays a partir do texto.\n",
    "import numpy as np\n",
    "\n",
    "# Oferece opções de redes neurais.\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Bibliotecas para a função on_epoch_end.\n",
    "import random, sys\n",
    "\n",
    "# Opções de configuração da compilação.\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo, após importarmos as bibliotecas acima, é informar à rede neural o texto que será utilizado para o aprendizado do modelo.\n",
    "\n",
    "Neste caso, assim como no exemplo original, o texto está disponível remotamente e pode ser acessado através deste [link](https://s3.amazonaws.com/text-datasets/nietzsche.txt). Ao executar a célula abaixo será feito o download automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origem remota do arquivo de texto utilizado no aprendizado do modelo.\n",
    "origin = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    "\n",
    "path = get_file(basename(origin), origin)\n",
    "\n",
    "# Faz a leitura do arquivo, deixando todos os caracteres minúsculos.\n",
    "with io.open(path, encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "    \n",
    "print(\"Tamanho do arquivo:\", len(text))\n",
    "\n",
    "# Verifica quantos caracteres diferentes existem no texto.\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print(\"Total de caracteres:\", len(chars))\n",
    "\n",
    "# Faz a indexação dos caracteres.\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, o algoritmo fatia o texto em sequências semi-redundantes, cuja quantidade de caracteres destas sequências é definida pela variável `maxlen`.\n",
    "\n",
    "Nada desta seção foi alterada em relação ao código-fonte original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho das fatias do texto.\n",
    "maxlen = 40\n",
    "\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Processo responsável por fatiar o texto em sequências.\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print(\"Total de sequências:\", len(sentences))\n",
    "\n",
    "print(\"\\nVetorizando as sequências...\")\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "        \n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "print(\"Sequências vetorizadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na próxima etapa vem a definição e construção do modelo de rede neural. Como se trata de uma rede neural recorrente do tipo LSTM, deve ser usada a implementação que a Keras oferece para se trabalhar com este tipo de modelo.\n",
    "\n",
    "Esta parte do código foi alterada para que retorne informações relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Construindo o modelo...\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# A camada de entrada é do tipo LSTM.\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "\n",
    "# Adiciona uma camada do tipo Dense com 24 neurônios e 0.2 de dropout.\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Adiciona uma camada do tipo Dense com 32 neurônios e 0.3 de dropout.\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Camada de saída.\n",
    "model.add(Dense(len(chars), activation=\"softmax\"))\n",
    "\n",
    "print(\"Modelo construído!\\n\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de partir para a compilação e treinamento, serão definidas duas funções que ajudarão nos processos. Elas são definidas, também, no exemplo original já citado.\n",
    "\n",
    "A função `sample` amostra um índice de uma matriz de probabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    \n",
    "    exp_preds = np.exp(preds)\n",
    "    \n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já a função `on_epoch_end` simplesmente mostra um *feedback* com algumas informações ao final de cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    print(\"\\n\\nGerando texto após época #{:d}...\".format(epoch + 1))\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(\"\\n{:->10s}\".format(\"\"))\n",
    "        print(\"Diversidade:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        \n",
    "        print(\"Gerando com a seed \\\"\" + sentence + \"\\\"\\n\")\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            \n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"{:s}{:->20s}\".format(\"\\n\" * 3, \"\"))\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora pode ser feita a configuração da compilação e treinamento deste modelo.\n",
    "\n",
    "Neste trecho vários parâmetros foram alterados do original, como o otimizador, o tamanho do *batch*, entre outros fatores.\n",
    "\n",
    "O mais importante a se notar, que inclusive é citado no texto da página do exemplo original, é que o modelo provavelmente irá gerar um texto coeso por volta da vigésima época, apenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy'],\n",
    "    optimizer=RMSprop()\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x, y,\n",
    "    batch_size=96,\n",
    "    epochs=64,\n",
    "    callbacks=[print_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cada época será gerado um texto usando diferentes *diversidades*. Quanto maior a diversidade, maior a \"mistura\" de caracteres empregada na geração, e, quanto mais avançada a época, mais coeso é o texto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
